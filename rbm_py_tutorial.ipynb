{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPsWozH/flCyh/yOm6XkH8u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuuki330/RBM/blob/main/rbm_py_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MNIST画像をRBMにて学習する基本実装\n"
      ],
      "metadata": {
        "id": "Oeh_0Aqp3Xe5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RBMクラスの定義"
      ],
      "metadata": {
        "id": "YhEyMstT3wki"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "QqgyXTntKmZJ"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision.transforms.functional as TF\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class RBM(nn.Module):\n",
        "    \"\"\"Restricted Boltzmann Machine. Default: Bernoulli-Bernoulli RBM\n",
        "    Args:\n",
        "        xsize: The number of visible units.\n",
        "        hsize: The number of hidden units. (Default: 100)\n",
        "        data_loader: Data Loader used to calculate initial parameter values. (Default: None)\n",
        "        k: The number of Gibbs sampling. (Default: 1)\n",
        "        winit: Initial values of weights. (Default: 0.001)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, xsize, hsize=100, data_loader=None, k=1, winit=0.001):\n",
        "        super(RBM, self).__init__()\n",
        "        if data_loader is None:\n",
        "            b0 = 0\n",
        "        else:\n",
        "            # just compute a mean vector of training data\n",
        "            # b0 = data_loader.dataset.data.mean(0)\n",
        "\n",
        "            ####### 変更 #######\n",
        "            b0 = data_loader.dataset.data.to(torch.float32).mean(0)\n",
        "            ###################\n",
        "\n",
        "        self.b = nn.Parameter(b0 * torch.ones(1, xsize))\n",
        "        self.c = nn.Parameter(-1 * torch.ones(1, hsize)) # to make h sparse\n",
        "        self.W = nn.Parameter(winit * torch.randn(hsize, xsize))\n",
        "        self.k = k\n",
        "\n",
        "    def rbmup(self, x):\n",
        "        h = torch.sigmoid(F.linear(x, self.W, self.c))\n",
        "        return h.bernoulli()\n",
        "\n",
        "    def rbmdown(self, h):\n",
        "        x = torch.sigmoid(F.linear(h, self.W.t(), self.b))\n",
        "        return x.bernoulli()\n",
        "\n",
        "    def sample(self, x):\n",
        "        h = self.rbmup(x)\n",
        "        for _ in range(self.k):\n",
        "            x_ = self.rbmdown(h)\n",
        "            h = self.rbmup(x_)\n",
        "        return x_\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Returns: free energy of input\n",
        "        \"\"\"\n",
        "        x_term = torch.matmul(x, self.b.t())\n",
        "        w_x_h = F.linear(x, self.W, self.c)\n",
        "        h_term = torch.sum(F.softplus(w_x_h), dim=1)\n",
        "        return torch.mean(- h_term - x_term)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mnist_transform(x):\n",
        "    x = x.view(-1, x.size(1)*x.size(2))\n",
        "    return x"
      ],
      "metadata": {
        "id": "eWYYJOMKMNRR"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SPXmPTrciZc3"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "idtKrzb_iZQ4"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##疑問点1(未解消)\n",
        "Totensor()では正規化処理が行われるはずなのに、試行1に示すように行われていない。\\\n",
        "しかし、試行2のように実行するとうまく動作するうまく動作する。-> 原因は不明\\\n",
        "また、試行3に示すように、無理矢理255で割ると結果が反映されるため、画像で実行する際は一時的にそのように実装するのが良さそう。"
      ],
      "metadata": {
        "id": "OZs9pcEh1oRP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 試行1\n",
        "\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "torch.set_printoptions(edgeitems=10)\n",
        "\n",
        "train_set = datasets.MNIST('./data', train=True, download=True)\n",
        "print(f'train_set.data[0] : {train_set.data[0].dtype}')\n",
        "\n",
        "# trans = transforms.ToTensor()\n",
        "train_set.data = train_set.data.numpy()\n",
        "# train_set.data = train_set.data.astype(np.uint8)\n",
        "tmp_data = TF.to_tensor(train_set.data)\n",
        "print(f'ToTensor後 train_set.data[0] : {tmp_data[0] > 0}')\n",
        "\n",
        "# mnist_transform()により、[N, 28, 28] -> [N, 784]へ変更\n",
        "# out_x = mnist_transform(train_set.data)\n",
        "# print(f'out_x[0] : {out_x[0]}')\n",
        "\n",
        "# 以下でも同様の処理が可能\n",
        "# train_set = train_set.reshape(-1, 784)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVPrRirMMPth",
        "outputId": "8f7a5181-4da7-44d5-b743-6cf72c71fee9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_set.data[0] : torch.uint8\n",
            "ToTensor後 train_set.data[0] : tensor([[False, False, False, False, False, False, False, False, False, False,\n",
            "          ..., False, False, False, False, False, False, False, False, False,\n",
            "         False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "          ..., False, False, False, False, False, False, False, False, False,\n",
            "         False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "          ..., False, False, False, False, False, False, False, False, False,\n",
            "         False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "          ..., False, False, False, False, False, False, False, False, False,\n",
            "         False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "          ..., False, False, False, False, False, False, False, False, False,\n",
            "         False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "          ..., False, False, False, False, False, False, False, False, False,\n",
            "         False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "          ..., False, False, False, False, False, False, False, False, False,\n",
            "         False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "          ..., False, False, False, False, False, False, False, False, False,\n",
            "         False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "          ..., False, False, False, False, False, False, False, False, False,\n",
            "         False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "          ..., False, False, False, False, False, False, False, False, False,\n",
            "         False],\n",
            "        ...,\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "          ..., False, False, False, False, False, False, False, False, False,\n",
            "         False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "          ..., False, False, False, False, False, False, False, False, False,\n",
            "         False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "          ..., False, False, False, False, False, False, False, False, False,\n",
            "         False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "          ..., False, False, False, False, False, False, False, False, False,\n",
            "         False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "          ..., False, False, False, False, False, False, False, False, False,\n",
            "         False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "          ..., False, False, False, False, False, False, False, False, False,\n",
            "         False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "          ..., False, False, False, False, False, False, False, False, False,\n",
            "         False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "          ..., False, False, False, False, False, False, False, False, False,\n",
            "         False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "          ..., False, False, False, False, False, False, False, False, False,\n",
            "         False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "          ..., False, False, False, False, False, False, False, False, False,\n",
            "         False]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 試行2\n",
        "\n",
        "a = np.full((3,3), 250, dtype=np.uint8)  # need uint8\n",
        "print(a)\n",
        "x = transforms.ToTensor()\n",
        "print(x(a))  # 0 ~ 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tl54tbFOcuXi",
        "outputId": "aadde6c8-dad4-4941-d910-e6c5eff58387"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[250 250 250]\n",
            " [250 250 250]\n",
            " [250 250 250]]\n",
            "tensor([[[0.9804, 0.9804, 0.9804],\n",
            "         [0.9804, 0.9804, 0.9804],\n",
            "         [0.9804, 0.9804, 0.9804]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 試行3\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Lambda(mnist_transform)])  # transfoems.Lambda()により値を0からから1へ正規化...されない\n",
        "train_set = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
        "print(f'train_set.data[0] : {train_set.data[0]}')\n",
        "\n",
        "train_set.data = train_set.data / 255\n",
        "print(f'train_set.data[0] : {train_set.data[0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0WI5oLcbq09",
        "outputId": "d68a368c-7ca7-4f6f-e549-ba4ee7d1ef62"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_set.data[0] : tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,\n",
            "          18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253,\n",
            "         253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253, 253,\n",
            "         253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253, 253,\n",
            "         198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253, 205,\n",
            "          11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,  90,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253, 190,\n",
            "           2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,\n",
            "          70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35, 241,\n",
            "         225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  81,\n",
            "         240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148,\n",
            "         229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221, 253,\n",
            "         253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253, 253,\n",
            "         253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253, 195,\n",
            "          80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,  11,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
            "       dtype=torch.uint8)\n",
            "train_set.data[0] : tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706, 0.4941, 0.5333,\n",
            "         0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1176,\n",
            "         0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
            "         0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922, 0.9333,\n",
            "         0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9843,\n",
            "         0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.8588,\n",
            "         0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137, 0.9686, 0.9451,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3137,\n",
            "         0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000, 0.1686, 0.6039,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275, 0.4235, 0.0039,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922, 0.9922, 0.4667,\n",
            "         0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294, 0.9922, 0.9922,\n",
            "         0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627, 0.3647, 0.9882,\n",
            "         0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9765,\n",
            "         0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098, 0.7176, 0.9922,\n",
            "         0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922, 0.9922, 0.9922,\n",
            "         0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922, 0.9922, 0.7882,\n",
            "         0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0902,\n",
            "         0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.3176, 0.0078,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706, 0.8588,\n",
            "         0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922, 0.9922,\n",
            "         0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922, 0.8314,\n",
            "         0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bpL6c3CBidaV"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TTYM-TVhidXa"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### データセットの定義とモデルのインスタンス作成"
      ],
      "metadata": {
        "id": "d4cysFYo4J0Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xsize = 28\n",
        "hsize = 10\n",
        "batch_size = 8\n",
        "seed = 1\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "device = device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Lambda(mnist_transform)])\n",
        "train_set = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "model = RBM(xsize=xsize, hsize=hsize, data_loader=train_loader).to(device)"
      ],
      "metadata": {
        "id": "QfVUSF_JK1zt"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glyxcdSltb-L",
        "outputId": "9ffed4f7-723a-44b6-db6b-8319393fd1e1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.]], device='cuda:0',\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PoDSPdjG4W-C"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eWU4VGsQ4W69"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 疑問点2(解消)\n",
        "rbmup()において、\\\n",
        "`RuntimeError: mat1 and mat2 must have the same dtype`\\\n",
        "というエラーが出る\\\n",
        "\\\n",
        "-> test_dataのdtypeが異なっていたため、torch.float32に変更したら解消した"
      ],
      "metadata": {
        "id": "lKkhiGJx4Xnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = train_loader.dataset.data.to(torch.float32)[0]\n",
        "print(f'test_data.shape : {test_data.shape}')\n",
        "print(f'test_data.type : {test_data.dtype}')\n",
        "\n",
        "winit=0.001\n",
        "c = nn.Parameter(-1 * torch.ones(1, hsize))\n",
        "W = nn.Parameter(winit * torch.randn(hsize, xsize))\n",
        "\n",
        "print(f'c.shape : {c.shape}')\n",
        "print(f'W.shape : {W.shape}')\n",
        "print(f'c.type : {c.dtype}')\n",
        "print(f'W.type : {W.dtype}')\n",
        "\n",
        "# F.linear(test_data, W, c)\n",
        "# F.linear(test_data, W, c)\n",
        "\n",
        "test_data = test_data.to(device)\n",
        "test_data_ = model.rbmup(test_data)\n",
        "print(test_data_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myY6RmCFK1xM",
        "outputId": "9b358330-95a7-437c-8bd9-21ed4cb1cff9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_data.shape : torch.Size([28, 28])\n",
            "test_data.type : torch.float32\n",
            "c.shape : torch.Size([1, 10])\n",
            "W.shape : torch.Size([10, 28])\n",
            "c.type : torch.float32\n",
            "W.type : torch.float32\n",
            "tensor([[0., 0., 0., 0., 1., 1., 1., 0., 0., 0.],\n",
            "        [1., 1., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 1., 0., 0., 1., 1., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0., 1., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 1., 0., 0., 0., 1., 0., 1.],\n",
            "        [0., 1., 1., 0., 0., 1., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 1., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0., 0., 1., 1.],\n",
            "        [1., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
            "        [1., 1., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 1., 1., 0., 0.],\n",
            "        [1., 0., 0., 0., 1., 1., 0., 1., 0., 0.],\n",
            "        [1., 1., 1., 0., 0., 0., 1., 1., 0., 0.],\n",
            "        [0., 0., 1., 0., 1., 1., 1., 1., 0., 1.],\n",
            "        [0., 1., 1., 0., 0., 1., 1., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 1., 1., 0., 0., 1., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 1., 0., 1., 0.],\n",
            "        [0., 1., 1., 0., 0., 0., 0., 1., 1., 1.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0., 1., 0., 0.],\n",
            "        [1., 0., 1., 0., 0., 0., 1., 0., 0., 0.]], device='cuda:0',\n",
            "       grad_fn=<BernoulliBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yHPEh76BK1uk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0-KfujcnK1se"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, n_epochs=20, lr=0.01, device=torch.device(\"cpu\")):\n",
        "    r\"\"\"Train a RBM model.\n",
        "    Args:\n",
        "        model: The model.\n",
        "        train_loader (DataLoader): The data loader.\n",
        "        n_epochs (int, optional): The number of epochs. Defaults to 20.\n",
        "        lr (Float, optional): The learning rate. Defaults to 0.01.\n",
        "    Returns:\n",
        "        The trained model.\n",
        "    \"\"\"\n",
        "    # optimizer\n",
        "    train_op = optim.Adam(model.parameters(), lr)\n",
        "\n",
        "    # train the RBM model\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        t = time.time()\n",
        "        loss_ = []\n",
        "        mse = 0\n",
        "        it = 0\n",
        "        for data, _ in train_loader:\n",
        "            x = data.to(device)\n",
        "            x_ = model.sample(x).detach()\n",
        "            loss = model(x) - model(x_)\n",
        "            loss_.append(loss.item())\n",
        "            train_op.zero_grad()\n",
        "            loss.backward()\n",
        "            train_op.step()\n",
        "            # x1 = x + torch.randn_like(x)\n",
        "            # x1.requires_grad = True\n",
        "            # x2 = model.sample_langevin(x1).detach()\n",
        "            with torch.no_grad():\n",
        "                mse += F.mse_loss(x, x_, reduction='sum')\n",
        "                # mse += F.mse_loss(x, x2, reduction='sum')\n",
        "\n",
        "        mse /= len(train_loader.dataset)\n",
        "        elapsed = time.time() - t\n",
        "        print('[Epoch %02d/%02d] (%.2f sec)\\t MSE=%.2f, Loss=%.2f, |W|=%.2f' % (epoch+1, n_epochs, elapsed, mse, np.mean(loss_), model.W.norm()))\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "Hy2g8mTdtD24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OtHm91NNtDwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OARnEQictDoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GaussRBM(RBM):\n",
        "    r\"\"\"Gaussian-Bernoulli RBM.\n",
        "    .. math::\n",
        "        \\begin{align}\n",
        "            E(x, h) = \\frac{1}{2} (\\frac{x}{\\sigma})^\\top (\\frac{x}{\\sigma}) - x^\\top W h -b^\\top x - c^\\top h\n",
        "        \\end{align}\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, xsize, hsize=100, data_loader=None, k=1, winit=0.001):\n",
        "        super(GaussRBM, self).__init__(xsize, hsize, data_loader, k, winit)\n",
        "        if data_loader is None:\n",
        "            z0 = 1\n",
        "        else:\n",
        "            z0 = data_loader.dataset.data.var(0)\n",
        "        self.z = nn.Parameter((z0 * torch.ones(1, xsize) + 1e-24).log()) # logvar\n",
        "        #self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        #self.z = (z0 * torch.ones(1, n_vis) + 1e-24).log().to(self.device)\n",
        "        self.use_langevin = False\n",
        "\n",
        "    def rbmdown(self, h):\n",
        "        mu = self.z.exp() * F.linear(h, self.W.t(), self.b)\n",
        "        x = torch.randn_like(mu) * (self.z.exp().sqrt()) + mu\n",
        "        return x\n",
        "\n",
        "    def sample_langevin(self, x_, steps=30, eta=1.0e-5):\n",
        "        eta = torch.tensor(eta)\n",
        "        for n in range(steps):\n",
        "            noise = torch.randn_like(x_)\n",
        "            out = -self.forward(x_)\n",
        "            out.backward()\n",
        "            x_.data.add_(0.5 * eta * x_.grad.data + torch.sqrt(eta) * noise.data)\n",
        "            x_.grad.detach_()\n",
        "            x_.grad.zero_()\n",
        "        return x_\n",
        "\n",
        "    def sample(self, x):\n",
        "        if self.use_langevin:\n",
        "            x_ = torch.randn_like(x, requires_grad=True)\n",
        "            return self.sample_langevin(x_)\n",
        "        else:\n",
        "            return super().sample(x)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_term = torch.matmul(self.b, x.t()) - ((x ** 2 / (self.z.exp())) / 2).sum(1)\n",
        "        w_x_h = F.linear(x, self.W, self.c)\n",
        "        h_term = torch.sum(F.softplus(w_x_h), dim=1)\n",
        "        return torch.mean(- h_term - x_term)"
      ],
      "metadata": {
        "id": "B-hYUGwJK1ot"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}